{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nwN1T2dG-P39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
            "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
            "[nltk_data]     unable to get local issuer certificate (_ssl.c:1123)>\n",
            "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
            "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
            "[nltk_data]     unable to get local issuer certificate (_ssl.c:1123)>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk   \n",
        "import spacy            \n",
        "import re     \n",
        "import string            \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import twitter_samples    # Corpus Twitter\n",
        "from nltk.tokenize import word_tokenize \n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Rf1sRZeM3Iz"
      },
      "source": [
        "Lectura de Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBrs994RL_OH",
        "outputId": "e8d6b5c8-909f-4cc2-ac81-2fc555f30a01"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading twitter_samples: <urlopen error [SSL:\n",
            "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
            "[nltk_data]     unable to get local issuer certificate (_ssl.c:1123)>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('twitter_samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7j31D_0MDA2",
        "outputId": "97f38f63-e161-4ce0-b25a-1c3dd5ad618c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive tweets:  5000\n",
            "Negative tweets:  5000\n"
          ]
        }
      ],
      "source": [
        "pos_tweets = twitter_samples.strings('positive_tweets.json') #tweets positivos\n",
        "neg_tweets = twitter_samples.strings('negative_tweets.json') #tweets negativos\n",
        "\n",
        "print(\"Positive tweets: \", len(pos_tweets))\n",
        "print(\"Negative tweets: \", len(neg_tweets))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F-An61QZMyWy"
      },
      "source": [
        "Procesamiento\n",
        "\n",
        "\n",
        "1. LowerCase\n",
        "2. Lematización / Stemming\n",
        "3. Remover stopword\n",
        "4. Remover signos de puntuación\n",
        "4. Remover urls y manejadores\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def custom_tokenizer(nlp):\n",
        "    special_cases = {\":)\": [{\"ORTH\": \":)\"}], \":(\": [{\"ORTH\": \":(\"}]}\n",
        "    simple_url_re = re.compile(r'''^https?://''')\n",
        "    suffixes = nlp.Defaults.suffixes + [r'''-+$''',]\n",
        "    prefixes = nlp.Defaults.prefixes + [r'^[\\-\\—\\–\\+\\+\\.\\!\\/\\,\\\"\\(\\)\\[\\]\\{\\}\\:\\;\\<\\>\\?\\¿\\¡\\|\\&\\#\\@\\$\\%\\^\\*\\_\\\\\\'\\`\\~]']\n",
        "    suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
        "    prefixes_regex = spacy.util.compile_prefix_regex(prefixes)\n",
        "    return spacy.tokenizer.Tokenizer(nlp.vocab, rules=special_cases, suffix_search=suffix_regex.search, prefix_search=prefixes_regex.search, url_match=simple_url_re.match)\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.tokenizer = custom_tokenizer(nlp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GVAU5JDMPhIx"
      },
      "outputs": [],
      "source": [
        "def normalization(data, regularization=\"lemma\", language='english'):\n",
        "  stopwords = nltk.corpus.stopwords.words(language)\n",
        "  ps = PorterStemmer()\n",
        "  normalized_data = []\n",
        "  \n",
        "  for tweet in data:\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet) # identificar retweets\n",
        "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet) #eliminar links\n",
        "    tweet = re.sub(r'#', '', tweet) #eliminar símbolo gato\n",
        "    tweet = re.sub(r'@\\w+', '', tweet) #eliminar palabras que inicias con @\n",
        "    tweet = re.sub(r'\\d+', '', tweet) #eliminar números\n",
        "    tweet = re.sub(' +', ' ', tweet) #quitar espacios\n",
        "\n",
        "    if regularization == \"stem\":\n",
        "      tweetTokenizer = TweetTokenizer()\n",
        "      words = tweetTokenizer.tokenize(tweet)\n",
        "      tokens = [ps.stem(w) for w in words]\n",
        "    if regularization == \"lemma\":\n",
        "      doc = nlp(tweet)\n",
        "      tokens = [token.lemma_ for token in doc]\n",
        "    else:\n",
        "      doc = nlp(tweet)\n",
        "      tokens = [token.text for token in doc]\n",
        "    \n",
        "    normalized_tweets = [w for w in tokens if w not in stopwords and not w==' ' and w not in string.punctuation]\n",
        "    normalized_data.append(normalized_tweets)\n",
        "  return normalized_data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create Vocabulary and frequency dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "norm_pos = normalization(pos_tweets)\n",
        "norm_neg = normalization(neg_tweets)\n",
        "all_tweets = norm_pos + norm_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def n_grams(words:list, n_gram:int):\n",
        "  if int(n_gram) == 1: return words\n",
        "  return [tuple(words[i:i+int(n_gram)]) for i,w in enumerate(words) if i <= (len(words)-int(n_gram))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The vocabulary has 40958 2-grams.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ngrams = 2\n",
        "n_grams_tweets = [n_grams(tweet, ngrams) for tweet in all_tweets]\n",
        "at = [w for tweet in n_grams_tweets for w in tweet]\n",
        "fd = nltk.FreqDist(at)\n",
        "vocabulary = sorted(list(fd.keys()))\n",
        "\n",
        "print('\\nThe vocabulary has ' + str(len(vocabulary)) + ' ' + str(ngrams) + '-grams.\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "X_features matrix has m = 10000 examples (rows).\n",
            "\n",
            "and  n = 40958 features (columns).\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_features = []\n",
        "for text in all_tweets:\n",
        "  vector = [] # initialize in 1 ?\n",
        "  for voc in vocabulary:\n",
        "    # In vector saves a list of vocabulary's length. \n",
        "    # Iterate each vocabulary word and count in each text list\n",
        "    vector.append(text.count(voc))\n",
        "  X_features.append(vector)\n",
        "\n",
        "print('\\nX_features matrix has m = %d examples (rows).\\n' %len(X_features))\n",
        "print('and  n = %d features (columns).\\n' %len(X_features[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "tags = [1]*len(pos_tweets) + [0]*len(neg_tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_features,tags,test_size=0.2, random_state=50)\n",
        "target_names = ['class 0', 'class 1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Puntaje:  0.4995\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0     0.0000    0.0000    0.0000      1001\n",
            "     class 1     0.4995    1.0000    0.6662       999\n",
            "\n",
            "    accuracy                         0.4995      2000\n",
            "   macro avg     0.2497    0.5000    0.3331      2000\n",
            "weighted avg     0.2495    0.4995    0.3328      2000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Crear un clasificador con DecisionTree\n",
        "modeloDT = DecisionTreeClassifier()\n",
        "# Entrenar el clasificador con los datos de entrenamiento\n",
        "modeloDT.fit(X_train, y_train)\n",
        "predicciones = modeloDT.predict(X_test)\n",
        "# Evaluamos el modelo\n",
        "puntaje = modeloDT.score(X_test, y_test)\n",
        "# Imprimimos el puntaje obtenido\n",
        "print(\"Puntaje: \", puntaje)\n",
        "print(classification_report(y_test, predicciones, target_names=target_names, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Puntaje:  0.5005\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0     0.5005    1.0000    0.6671      1001\n",
            "     class 1     0.0000    0.0000    0.0000       999\n",
            "\n",
            "    accuracy                         0.5005      2000\n",
            "   macro avg     0.2502    0.5000    0.3336      2000\n",
            "weighted avg     0.2505    0.5005    0.3339      2000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Crear un clasificador con RandomForest\n",
        "modeloRF = RandomForestClassifier()\n",
        "# Entrenar el clasificador con los datos de entrenamiento\n",
        "modeloRF.fit(X_train, y_train)\n",
        "predicciones = modeloRF.predict(X_test)\n",
        "# Evaluamos el modelo\n",
        "puntaje = modeloRF.score(X_test, y_test)\n",
        "# Imprimimos el puntaje obtenido\n",
        "print(\"Puntaje: \", puntaje)\n",
        "print(classification_report(y_test, predicciones, target_names=target_names, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Puntaje:  0.4995\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0     0.0000    0.0000    0.0000      1001\n",
            "     class 1     0.4995    1.0000    0.6662       999\n",
            "\n",
            "    accuracy                         0.4995      2000\n",
            "   macro avg     0.2497    0.5000    0.3331      2000\n",
            "weighted avg     0.2495    0.4995    0.3328      2000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Crear un clasificador con SVC\n",
        "modeloSVC = SVC(kernel='linear', random_state=42)\n",
        "# Entrenar el clasificador con los datos de entrenamiento\n",
        "modeloSVC.fit(X_train, y_train)\n",
        "predicciones = modeloSVC.predict(X_test)\n",
        "# Evaluamos el modelo\n",
        "puntaje = modeloSVC.score(X_test, y_test)\n",
        "# Imprimimos el puntaje obtenido\n",
        "print(\"Puntaje: \", puntaje)\n",
        "print(classification_report(y_test, predicciones, target_names=target_names, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Puntaje:  0.4995\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0     0.0000    0.0000    0.0000      1001\n",
            "     class 1     0.4995    1.0000    0.6662       999\n",
            "\n",
            "    accuracy                         0.4995      2000\n",
            "   macro avg     0.2497    0.5000    0.3331      2000\n",
            "weighted avg     0.2495    0.4995    0.3328      2000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Crear un clasificador con AdaBoostClassifier\n",
        "modeloADA = AdaBoostClassifier()\n",
        "# Entrenar el clasificador con los datos de entrenamiento\n",
        "modeloADA.fit(X_train, y_train)\n",
        "predicciones = modeloADA.predict(X_test)\n",
        "# Evaluamos el modelo\n",
        "puntaje = modeloADA.score(X_test, y_test)\n",
        "# Imprimimos el puntaje obtenido\n",
        "print(\"Puntaje: \", puntaje)\n",
        "print(classification_report(y_test, predicciones, target_names=target_names, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Puntaje:  0.4995\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0     0.0000    0.0000    0.0000      1001\n",
            "     class 1     0.4995    1.0000    0.6662       999\n",
            "\n",
            "    accuracy                         0.4995      2000\n",
            "   macro avg     0.2497    0.5000    0.3331      2000\n",
            "weighted avg     0.2495    0.4995    0.3328      2000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Crear un clasificador con KNeighborsClassifier\n",
        "modeloKN = KNeighborsClassifier()\n",
        "# Entrenar el clasificador con los datos de entrenamiento\n",
        "modeloKN.fit(X_train, y_train)\n",
        "predicciones = modeloKN.predict(X_test)\n",
        "# Evaluamos el modelo\n",
        "puntaje = modeloKN.score(X_test, y_test)\n",
        "# Imprimimos el puntaje obtenido\n",
        "print(\"Puntaje: \", puntaje)\n",
        "print(classification_report(y_test, predicciones, target_names=target_names, digits=4))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
