{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nwN1T2dG-P39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
            "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
            "[nltk_data]     unable to get local issuer certificate (_ssl.c:1123)>\n",
            "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
            "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
            "[nltk_data]     unable to get local issuer certificate (_ssl.c:1123)>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk   \n",
        "import spacy            \n",
        "import re     \n",
        "import string            \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import twitter_samples    # Corpus Twitter\n",
        "from nltk.tokenize import word_tokenize \n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Rf1sRZeM3Iz"
      },
      "source": [
        "Lectura de Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBrs994RL_OH",
        "outputId": "e8d6b5c8-909f-4cc2-ac81-2fc555f30a01"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading twitter_samples: <urlopen error [SSL:\n",
            "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
            "[nltk_data]     unable to get local issuer certificate (_ssl.c:1123)>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('twitter_samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7j31D_0MDA2",
        "outputId": "97f38f63-e161-4ce0-b25a-1c3dd5ad618c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive tweets:  5000\n",
            "Negative tweets:  5000\n"
          ]
        }
      ],
      "source": [
        "pos_tweets = twitter_samples.strings('positive_tweets.json') #tweets positivos\n",
        "neg_tweets = twitter_samples.strings('negative_tweets.json') #tweets negativos\n",
        "\n",
        "print(\"Positive tweets: \", len(pos_tweets))\n",
        "print(\"Negative tweets: \", len(neg_tweets))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F-An61QZMyWy"
      },
      "source": [
        "Procesamiento\n",
        "\n",
        "\n",
        "1. LowerCase\n",
        "2. Lematización / Stemming\n",
        "3. Remover stopword\n",
        "4. Remover signos de puntuación\n",
        "4. Remover urls y manejadores\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def custom_tokenizer(nlp):\n",
        "    special_cases = {\":)\": [{\"ORTH\": \":)\"}], \":(\": [{\"ORTH\": \":(\"}]}\n",
        "    simple_url_re = re.compile(r'''^https?://''')\n",
        "    suffixes = nlp.Defaults.suffixes + [r'''-+$''',]\n",
        "    prefixes = nlp.Defaults.prefixes + [r'^[\\-\\—\\–\\+\\+\\.\\!\\/\\,\\\"\\(\\)\\[\\]\\{\\}\\:\\;\\<\\>\\?\\¿\\¡\\|\\&\\#\\@\\$\\%\\^\\*\\_\\\\\\'\\`\\~]']\n",
        "    suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
        "    prefixes_regex = spacy.util.compile_prefix_regex(prefixes)\n",
        "    return spacy.tokenizer.Tokenizer(nlp.vocab, rules=special_cases, suffix_search=suffix_regex.search, prefix_search=prefixes_regex.search, url_match=simple_url_re.match)\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.tokenizer = custom_tokenizer(nlp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GVAU5JDMPhIx"
      },
      "outputs": [],
      "source": [
        "def normalization(data, regularization=\"lemma\", language='english'):\n",
        "  stopwords = nltk.corpus.stopwords.words(language)\n",
        "  ps = PorterStemmer()\n",
        "  normalized_data = []\n",
        "  \n",
        "  for tweet in data:\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet) # identificar retweets\n",
        "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet) #eliminar links\n",
        "    tweet = re.sub(r'#', '', tweet) #eliminar símbolo gato\n",
        "    tweet = re.sub(r'@\\w+', '', tweet) #eliminar palabras que inicias con @\n",
        "    tweet = re.sub(r'\\d+', '', tweet) #eliminar números\n",
        "    tweet = re.sub(' +', ' ', tweet) #quitar espacios\n",
        "\n",
        "    if regularization == \"stem\":\n",
        "      tweetTokenizer = TweetTokenizer()\n",
        "      words = tweetTokenizer.tokenize(tweet)\n",
        "      tokens = [ps.stem(w) for w in words]\n",
        "    if regularization == \"lemma\":\n",
        "      doc = nlp(tweet)\n",
        "      tokens = [token.lemma_ for token in doc]\n",
        "    else:\n",
        "      doc = nlp(tweet)\n",
        "      tokens = [token.text for token in doc]\n",
        "    \n",
        "    normalized_tweets = [w for w in tokens if w not in stopwords and not w==' ' and w not in string.punctuation]\n",
        "    normalized_data.append(normalized_tweets)\n",
        "  return normalized_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "norm_pos = normalization(pos_tweets)\n",
        "norm_neg = normalization(neg_tweets)\n",
        "all_tweets = norm_pos + norm_neg\n",
        "tags = [1]*len(norm_pos) + [0]*len(norm_neg)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Shuffle samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Shuffle samples\"\"\"\n",
        "tuple_list = list(zip(all_tweets, tags)) #list of tuples (X,y)\n",
        "random.seed(30)\n",
        "random.shuffle(tuple_list)\n",
        "X_, y_ = zip(*tuple_list)\n",
        "\n",
        "X = list(X_)\n",
        "y = list(y_)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split Corpus in test and train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_percentage = 0.2\n",
        "split = int(len(X) * test_percentage)\n",
        "X_test = X[:split]\n",
        "y_test = y[:split]\n",
        "X_train = X[split:]\n",
        "y_train = y[split:]\n",
        "\n",
        "m_train = len(X_train) #number of examples in X_train\n",
        "m_test = len(X_test) #number of examples in X_test"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calcular freq(w,class_of_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_frequencies(normalized_tweets, y):\n",
        "    pos_freqs_dict, neg_freqs_dict = {}, {}\n",
        "    for i, tweet in enumerate(normalized_tweets):\n",
        "        for word in tweet:\n",
        "            if y[i] == 1: #positive sentiment\n",
        "                pos_freqs_dict[(word,1)] = pos_freqs_dict.get((word,1), 0) + 1\n",
        "            else:\n",
        "                #negative sentiment\n",
        "                neg_freqs_dict[(word,0)] = neg_freqs_dict.get((word,0), 0) + 1\n",
        "    return pos_freqs_dict, neg_freqs_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "pos_freqs_dict, neg_freqs_dict = build_frequencies(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pos_freqs_dict"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "at = [w for tweet in X_train for w in tweet]\n",
        "fd = nltk.FreqDist(at)\n",
        "vocabulary = sorted(list(fd.keys()))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calcular N_class y tamaño de vocabulario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of words of the positive class:  27931\n",
            "Number of words of the negative class:  29009\n",
            "Vocabulary size:  10739\n"
          ]
        }
      ],
      "source": [
        "N_pos_class = sum(list(pos_freqs_dict.values()))\n",
        "N_neg_class = sum(list(neg_freqs_dict.values()))\n",
        "len_voc = len(vocabulary)\n",
        "print(\"Number of words of the positive class: \", N_pos_class)\n",
        "print(\"Number of words of the negative class: \", N_neg_class)\n",
        "print(\"Vocabulary size: \", len_voc)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calcular probabilidad condicional P(w|class)\n",
        "\n",
        "Probabilidad de que una palabra se encuentre en una clase (sentimiento positivo o negativo)\n",
        "\n",
        "Se hace uso de laplacian smoothing :\n",
        "\n",
        "P(w_i|class) = (freq(w_i,class) + 1) / (N_class + len_voc)\n",
        "\n",
        "Donde N_class puede ser N_pos_class y N_neg_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def P__w_i_given_class__(freqs_dict, N_class, vocabulary, len_voc):\n",
        "    #positive sentiment = 1\n",
        "    #negative sentiment = 0\n",
        "    sentiment = list(freqs_dict)[0][1]\n",
        "    prob_dict = {}\n",
        "    for word in vocabulary:\n",
        "        freq = freqs_dict.get((word,sentiment), 0)\n",
        "        #Use laplace smoothing\n",
        "        prob_dict[(word,sentiment)] = ((freq + 1) / (N_class + len_voc))\n",
        "    return prob_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "pos_prob_dict = P__w_i_given_class__(pos_freqs_dict, N_pos_class, vocabulary, len_voc)\n",
        "neg_prob_dict = P__w_i_given_class__(neg_freqs_dict, N_neg_class, vocabulary, len_voc)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtener lambda expresado como logaritmo\n",
        "\n",
        "Calcular log-likelihood, Regla de condición de inferencia para clasificación binaria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lambda_ratio(vocabulary, pos_prob_dict, neg_prob_dict):\n",
        "    lambda_dict = {}\n",
        "    #positive sentiment = 1\n",
        "    #negative sentiment = 0\n",
        "    for word in vocabulary:\n",
        "        prob_w_given_pos_ = pos_prob_dict[(word,1)]\n",
        "        prob_w_given_neg_ = neg_prob_dict[(word,0)]\n",
        "        lambda_dict[word] = math.log(prob_w_given_pos_/prob_w_given_neg_)\n",
        "    return lambda_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "lambda_dict = lambda_ratio(vocabulary, pos_prob_dict, neg_prob_dict)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtener log prior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_prior = math.log(len(pos_tweets)/len(neg_tweets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_likelihood_per_tweet(tweet, lambda_dict, log_prior):\n",
        "    log_likelihood = [lambda_dict.get(word, 0) for word in tweet]\n",
        "    return sum([log_prior] + log_likelihood)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [],
      "source": [
        "def naive_bayes_evaluation(X, lambda_dict, log_prior):\n",
        "    y_pred = []\n",
        "    for tweet in X:\n",
        "        likelihood_per_tweet = calculate_likelihood_per_tweet(tweet, lambda_dict, log_prior)\n",
        "        sentiment_pred = 1 if likelihood_per_tweet > 0 else 0\n",
        "        y_pred.append(sentiment_pred)\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "def confusion_matrix_values(y_pred, y_label):\n",
        "  TP, FN, FP, TN = 0 , 0 , 0, 0\n",
        "  for i in range(len(y_pred)):\n",
        "    if y_pred[i] == 1 and  y_label[i] == 1:\n",
        "      TP = TP + 1\n",
        "    elif y_pred[i] == 1 and y_label[i] == 0:\n",
        "      FP = FP + 1\n",
        "    elif y_pred[i] == 0 and y_label[i] == 1:\n",
        "      FN = FN + 1\n",
        "    else:\n",
        "      TN = TN + 1\n",
        "  return TP, FN, FP, TN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Measures\"\"\"\n",
        "\n",
        "def measures(TP, FN, FP, TN):\n",
        "  accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "  fallout = FP / (FP + TN)\n",
        "  precision = TP / (TP + FP)\n",
        "  recall = TP / (TP + FN)\n",
        "  F = (precision * recall) / (precision + recall)\n",
        "  F1 = (2 * precision * recall)/(precision + recall)\n",
        "  print(\"Presicion: \", precision)\n",
        "  print(\"Recall: \", recall)\n",
        "  print(\"F: \", F)\n",
        "  print(\"F1: \", F1)\n",
        "  print(\"Fallout: \", fallout)\n",
        "  print(\"Accuracy: \", accuracy)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluación para conjunto de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVALUATION FOR TRAIN SET: \n",
            "3825 160 44 3971\n",
            "Presicion:  0.9886275523391057\n",
            "Recall:  0.9598494353826851\n",
            "F:  0.487012987012987\n",
            "F1:  0.974025974025974\n",
            "Fallout:  0.010958904109589041\n",
            "Accuracy:  0.9745\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Evaluation for Train\"\"\"\n",
        "y_train_pred = naive_bayes_evaluation(X_train, lambda_dict, log_prior)\n",
        "TP, FN, FP, TN = confusion_matrix_values(y_train_pred, y_train)\n",
        "print(\"EVALUATION FOR TRAIN SET: \")\n",
        "print(TP,FN,FP,TN)\n",
        "measures(TP,FN,FP,TN)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluación para conjunto de prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVALUATION FOR TEST SET: \n",
            "927 88 28 957\n",
            "Presicion:  0.9706806282722513\n",
            "Recall:  0.9133004926108375\n",
            "F:  0.4705583756345178\n",
            "F1:  0.9411167512690356\n",
            "Fallout:  0.028426395939086295\n",
            "Accuracy:  0.942\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Evaluation for Test\"\"\"\n",
        "y_test_pred = naive_bayes_evaluation(X_test, lambda_dict, log_prior)\n",
        "TP, FN, FP, TN = confusion_matrix_values(y_test_pred, y_test)\n",
        "print(\"EVALUATION FOR TEST SET: \")\n",
        "print(TP,FN,FP,TN)\n",
        "measures(TP,FN,FP,TN)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4 (v3.9.4:1f2e3088f3, Apr  4 2021, 12:32:44) \n[Clang 6.0 (clang-600.0.57)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
